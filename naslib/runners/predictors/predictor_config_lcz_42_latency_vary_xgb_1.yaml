# The experiment type can be single, vary_train_size, vary_fidelity, or vary_both
# single will use train_size_single and fidleity_single 
# vary_train_size will use train_size_list and fidelity_single
# vary_fidelity will use train_size_single and fidelity_list
# vary_both will use train_size_list and fidelity_list
experiment_type: vary_train_size

# nasbench101, nasbench201, darts, nlp, transbench101_micro
#search_space: nasbench201
search_space: nasbench101

# nasbench201 datasets: cifar10, cifar100, ImageNet16-120
# transbench101 datasets: class_scene, class_object,
# jigsaw, room_layout, segmentsemantic, normal, autoencoder
# so2sat_lcz42_micro, so2sat_lcz42_macro, so2sat_lcz42_latency, so2sat_lcz42_MACs
dataset: so2sat_lcz42_latency

# one of the 31 predictors in benchmarks/predictors/runner.py
#predictor: synflow
#predictor: mlp, xgb, lgb, gp, dngo, gp_path, etc
predictor: xgb

# 0: mutation-based, or 1: uniformly random, train/test sets
uniform_random: 1

# test set size
test_size: 100

# size of the training set (used by model-based predictors)
train_size_single: 10
train_size_list: [200, 300, 400, 500, 750, 800, 900]

# num. epochs to train the test set arches (used by learning curve methods)
fidelity_single: 5
fidelity_list: [1, 2, 3, 5, 7, 9, 13, 19, 26, 37, 52, 73]

# output results to this directory
out_dir: run

# maximum number of seconds to run cross-validation (for model-based predictors)
max_hpo_time: 0

# load the hyperparams from the specified file.
# otherwise, set to None or False
hparams_from_file: predictor_hpo_configs/hpo_config_1.json

# random seed
seed: 1

# these are used by the zero-cost methods
search:
  batch_size: 256
  data_size: 25000
  cutout: False
  cutout_length: 16
  cutout_prob: 1.0
  train_portion: 0.7
