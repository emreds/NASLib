{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook is a modified version of *Sample Architecture* to try out So2Sat LCZ42 Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "device: cpu\n",
      "device: cpu\n",
      "device: cpu\n",
      "device: cpu\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from naslib.defaults.trainer import Trainer\n",
    "\n",
    "from naslib.search_spaces import (\n",
    "    DartsSearchSpace,\n",
    "    SimpleCellSearchSpace,\n",
    "    NasBench101SearchSpace,\n",
    "    HierarchicalSearchSpace,\n",
    ")\n",
    "from naslib.search_spaces.nasbench101 import graph\n",
    "\n",
    "from naslib.utils import get_dataset_api, setup_logger, utils\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.get_config_from_args(config_type=\"nas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from file... This may take a few minutes...\n",
      "Loaded dataset in 3 seconds\n"
     ]
    }
   ],
   "source": [
    "dataset_api = get_dataset_api(config.search_space, config.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Cell Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"input\"\n",
    "OUTPUT = \"output\"\n",
    "CONV3X3 = \"conv3x3-bn-relu\"\n",
    "CONV1X1 = \"conv1x1-bn-relu\"\n",
    "MAXPOOL3X3 = \"maxpool3x3\"\n",
    "OPS = [CONV3X3, CONV1X1, MAXPOOL3X3]\n",
    "\n",
    "NUM_VERTICES = 7\n",
    "OP_SPOTS = NUM_VERTICES - 2\n",
    "MAX_EDGES = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_architecture(dataset_api, arch_limit=10):\n",
    "        \"\"\"\n",
    "        This will sample a random architecture and update the edges in the\n",
    "        naslib object accordingly.\n",
    "        From the NASBench repository:\n",
    "        one-hot adjacency matrix\n",
    "        draw [0,1] for each slot in the adjacency matrix\n",
    "        \"\"\"\n",
    "        architectures = []\n",
    "        while len(architectures) < arch_limit:\n",
    "            matrix = np.random.choice([0, 1], size=(NUM_VERTICES, NUM_VERTICES))\n",
    "            matrix = np.triu(matrix, 1)\n",
    "            ops = np.random.choice(OPS, size=NUM_VERTICES).tolist()\n",
    "            ops[0] = INPUT\n",
    "            ops[-1] = OUTPUT\n",
    "            spec = dataset_api[\"api\"].ModelSpec(matrix=matrix, ops=ops)\n",
    "            if dataset_api[\"nb101_data\"].is_valid(spec):\n",
    "                architectures.append({\"matrix\": matrix, \"ops\": ops})\n",
    "                #break\n",
    "        \n",
    "        return architectures\n",
    "            \n",
    "        #self.set_spec({\"matrix\": matrix, \"ops\": ops})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_architectures = sample_random_architecture(dataset_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the architecture into Pytorch Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naslib.predictors.utils.models import nasbench1 as nas101_arch\n",
    "from naslib.predictors.utils.models import nasbench1_spec\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are using cifar10 to sample a network, keep in mind that So2Sat LCZ42 **17** classes \n",
    "* We need to change the input featurs to **10** for sentinel-2 in **naslib/predictors/utils/models/nasbench1.py** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = nasbench1_spec._ToModelSpec(\n",
    "    sampled_architectures[0][\"matrix\"], sampled_architectures[0][\"ops\"]\n",
    ")\n",
    "\n",
    "# change cofar10 output feature to 17\n",
    "num_classes_dic = {\"cifar10\": 17, \"cifar100\": 100, \"ImageNet16-120\": 120}\n",
    "\n",
    "network = nas101_arch.Network(\n",
    "    spec,\n",
    "    stem_out=128,\n",
    "    num_stacks=3,\n",
    "    num_mods=3,\n",
    "    num_classes=num_classes_dic[\"cifar10\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network, './network0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_1 = torch.load('./network0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the network for `So2Sat LCZ42` classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_device = network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "naslib.predictors.utils.models.nasbench1.Network"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(on_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pre-calculated mean and std values for sentinel-2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_mean = [\n",
    "1.237384229898452759e-01,1.092514395713806152e-01,1.010472476482391357e-01,\n",
    "1.141963005065917969e-01,1.592123955488204956e-01,1.814149618148803711e-01,\n",
    "1.745131611824035645e-01,1.949533522129058838e-01,1.542119830846786499e-01,\n",
    "1.089953780174255371e-01]\n",
    "training_data_std = [\n",
    "3.955886885523796082e-02,4.774657264351844788e-02,6.632962822914123535e-02,\n",
    "6.356767565011978149e-02,7.745764404535293579e-02,9.104172885417938232e-02,\n",
    "9.217569977045059204e-02,1.016793847084045410e-01,9.986902773380279541e-02,\n",
    "8.776713907718658447e-02\n",
    "]\n",
    "validation_data_mean = [\n",
    "1.289583146572113037e-01,1.164120137691497803e-01,1.122049614787101746e-01,\n",
    "1.240097358822822571e-01,1.646174490451812744e-01,1.862829625606536865e-01,\n",
    "1.791501641273498535e-01,2.004020363092422485e-01,1.738285273313522339e-01,\n",
    "1.277212053537368774e-01]\n",
    "validation_data_std = [\n",
    "3.845561295747756958e-02,4.351711273193359375e-02,5.868862569332122803e-02,\n",
    "5.489562824368476868e-02,6.446107476949691772e-02,7.579671591520309448e-02,\n",
    "7.847409695386886597e-02,8.553111553192138672e-02,9.418702870607376099e-02,\n",
    "8.428058028221130371e-02\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomCrop(32, padding=4),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(training_data_mean, training_data_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "valid_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(validation_data_mean, validation_data_std),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To be able to use custom data loader, EODataLoader, we need to specify the path of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import sys\n",
    "sys.path.append(path.abspath('../../../repository/tum-dlr-automl-for-eo/src/tum_dlr_automl_for_eo/datamodules'))\n",
    "from EODataLoader import EODataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data set should be under a file named So2SatLCZ, if this path does not exist it will download the data in the following step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = EODataModule('/Users/safayilmaz/Desktop/DI LAB', 'Sentinel-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This step will prepare the data, namely download it if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-30 09:50:31,704 - Data preparation is done, next step is data set-up\n"
     ]
    }
   ],
   "source": [
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **setup_training_data, setup_validation_data, and setup_testing_data** will read the data from downloaded paths, and apply specified transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-30 09:50:33,448 - Number of training data: 352366\n",
      "2022-11-30 09:50:33,449 - Number of classes: 17\n"
     ]
    }
   ],
   "source": [
    "data_module.setup_training_data(train_transform)\n",
    "batch_size = 64\n",
    "training_data = data_module.training_dataLoader(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-30 09:50:36,547 - Number of validation data: 24119\n",
      "2022-11-30 09:50:36,548 - Number of classes: 17\n"
     ]
    }
   ],
   "source": [
    "data_module.setup_validation_data(valid_transform)\n",
    "validation_data = data_module.validation_dataLoader(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy\n",
    "lr = 0.4\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%| | 393/5506 [26:19<5:41:36,  4.01s/batch, accuracy=1.56, loss=nan]"
     ]
    }
   ],
   "source": [
    "network.train()\n",
    "for epoch in range(1, 5):\n",
    "    with tqdm(training_data, unit=\"batch\") as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data.float())\n",
    "            predictions = output.argmax(dim=1, keepdim=True).squeeze()\n",
    "            loss = F.nll_loss(output, target)\n",
    "            correct = (predictions == target).sum().item()\n",
    "            accuracy = correct / batch_size\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy)\n",
    "            sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbaa411444fd0f6a0219be7247cafe8232f9ca19b314371503f22ac5d4b08631"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
